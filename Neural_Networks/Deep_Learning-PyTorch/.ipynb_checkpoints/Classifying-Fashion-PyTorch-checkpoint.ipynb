{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Fashion-MNIST\n",
    "\n",
    "Now it's your turn to build and train a neural network. You'll be using the [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist), a drop-in replacement for the MNIST dataset. MNIST is actually quite trivial with neural networks where you can easily achieve better than 97% accuracy. Fashion-MNIST is a set of ***28x28 greyscale images of clothes***. It's more complex than MNIST, so it's a better representation of the actual performance of your network, and a better representation of datasets you'll use in the real world.\n",
    "\n",
    "<img src='assets/fashion-mnist-sprite.png' width=500px>\n",
    "\n",
    "In this notebook, you'll build your own neural network. It's important for you to write the code yourself and get it to work. Feel free to consult the previous notebooks though as you work through this.\n",
    "\n",
    "First off, let's load the dataset through torchvision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "%matplotlib inline\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1975e8b4c48>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets Preview this Dataset\n",
    "image, label = next(iter(trainloader))\n",
    "helper.imshow(image[0,:]) # Show first image, all pixeLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "\n",
    "Here you should define your network. As with MNIST, each image is 28x28 which is a total of 784 pixels, and there are 10 classes. You should include at least one hidden layer. We suggest you use ReLU activations for the layers and to return the logits or log-softmax from the forward pass. It's up to you how many layers you add and the size of those layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter\n",
    "epochs = 10\n",
    "lr_ = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128,56),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(56,28),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(28,10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "# log-softmax output, you want to use the negative log likelihood loss, nn.NLLLoss\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network\n",
    "\n",
    "Now you should create your network and train it. First you'll want to define [the criterion](http://pytorch.org/docs/master/nn.html#loss-functions) ( something like `nn.CrossEntropyLoss`) and [the optimizer](http://pytorch.org/docs/master/optim.html) (typically `optim.SGD` or `optim.Adam`).\n",
    "\n",
    "Then write the training code. Remember the training pass is a fairly straightforward process:\n",
    "\n",
    "* Make a forward pass through the network to get the logits \n",
    "* Use the logits to calculate the loss\n",
    "* Perform a backward pass through the network with `loss.backward()` to calculate the gradients\n",
    "* Take a step with the optimizer to update the weights\n",
    "\n",
    "By adjusting the hyperparameters (hidden units, learning rate, etc), you should be able to get the training loss below 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5611186372255211\n",
      "Training loss: 0.39161655894601777\n"
     ]
    }
   ],
   "source": [
    "#Adam Gradient Descent Optimizer - Batch Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr_)\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    \n",
    "    # For each batch of images\n",
    "    for images,labels in trainloader:\n",
    "        \n",
    "        #Flatten\n",
    "        images = images.view(images.shape[0],-1)\n",
    "        \n",
    "        # Train Pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Foward Pass\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        # Backward Pass\n",
    "        loss.backward() # Calculate Gradients with respect to weigths\n",
    "        optimizer.step() # Backpropagate, correct weights\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")\n",
    "        \n",
    "print(\"Done Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "img = images[1]\n",
    "\n",
    "s = model(img)\n",
    "print(s)\n",
    "\n",
    "# Plot the image and probabilities\n",
    "helper.view_classify(img, ps, version='Fashion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
