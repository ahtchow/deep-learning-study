{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Applications\n",
    "\n",
    " - Natural Language Processing\n",
    " - Computer Vision\n",
    " - Voice User Interfacing (WaveNet)\n",
    " - Playing video games\n",
    " - Drone, Robotics\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a Feature\n",
    "\n",
    "I’ve found that a helpful way to think about what a feature is, is to think about what we are visually drawn to when we first see an object and when we identify different objects. For example, what do we look at to distinguish a cat and a dog? The shape of the eyes, the size, and how they move are just a couple of examples of visual features. Next, we’ll see that features like these can be measured, and represented as numerical data, by a machine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Computer Intepret Images\n",
    "\n",
    "- Grid a values, where each pixel is a value\n",
    "- L by W array, with D depth\n",
    "\n",
    "\n",
    "# Normalizing Image Inputs\n",
    "\n",
    "- Helps Gradient Calculation, ensures standard distribution\n",
    "- Scales all pixel values to 0 to 1, by dividing all pixels by 255\n",
    "\n",
    "Data normalization is typically done by subtracting the mean (the average of all pixel values) from each pixel, and then dividing the result by the standard deviation of all the pixel values. Sometimes you'll see an approximation here, where we use a mean and standard deviation of 0.5 to center the pixel values.\n",
    "\n",
    "The distribution of such data should resemble a Gaussian function centered at zero. For image inputs we need the pixel numbers to be positive, so we often choose to scale the data in a normalized range [0,1].\n",
    "\n",
    "***Flattening*** : turning a 2-D Image into a 1D array (28x28 = 1x784) , this is a typical input to a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Structure and Class Scores\n",
    "\n",
    "- At this point our images have been converted into flattened array (1x784)\n",
    "- ***Class Score*** - Propabilistic value associated with an output class\n",
    "\n",
    "![q](cnn_img/q1.png)\n",
    "\n",
    "### How do we know the structure of our MLP?\n",
    "\n",
    "- The multilayered perceptron can be composed of many hidden layers. Typically start by searching for research papers associated with the same task.\n",
    "- Most MLP for Mnist datasets use 1 hidden layer, but lets use 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and Optimization\n",
    "\n",
    "![q](cnn_img/q2.png)\n",
    "\n",
    "### How does a machine learn from its mistakes?\n",
    "\n",
    "1. Measures error using a loss function\n",
    "2. Backprogragation - calculate Gradients\n",
    "3. Optimization Function (i.e Gradient Descent) to redjust weights\n",
    "\n",
    "### Output layer scores must be interpretable.\n",
    "\n",
    "- Common: Apply Softmax to convert scores to probability\n",
    "\n",
    "![q](cnn_img/q4.png)\n",
    "\n",
    " - We then compare the scores in response to the real label, calculate error\n",
    " - Loss Function: (I.e Categorical Cross-Entropy Loss)\n",
    " - Categorical Cross Entropy takes to Negative Log of the each score as its loss\n",
    " - loss is lower when more accurate\n",
    "\n",
    "![q](cnn_img/q5.png)\n",
    "\n",
    "Next we need to explore optimizers to perform weight optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relu Activation Function\n",
    "\n",
    "The purpose of an activation function is to scale the outputs of a layer so that they are a consistent, small value. Much like normalizing input values, this step ensures that our model trains efficiently!\n",
    "\n",
    "A ReLU activation function stands for \"Rectified Linear Unit\" and is one of the most commonly used activation functions for hidden layers. It is an activation function, simply defined as the positive part of the input, x. So, for an input image with any negative pixel values, this would turn all those values to 0, black. You may hear this referred to as \"clipping\" the values to zero; meaning that is the lower bound.\n",
    "\n",
    "![q](cnn_img/q6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
